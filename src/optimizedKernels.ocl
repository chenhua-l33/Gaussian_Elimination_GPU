#pragma OPENCL EXTENSION cl_amd_printf : enable 

//////////////////////////////////////////////////
// OPTIMIZED GAUSSIAN ELIMINATION KERNELS        //
//////////////////////////////////////////////////

/**
 * This file contains three optimized implementations of Gaussian Elimination:
 * 1. Block-based with shared memory optimization
 * 2. Coalesced memory access version
 * 3. Compute-intensive version for benchmarking
 * 
 * Each implementation targets different performance aspects:
 * - Block-based: Reduces global memory access through local memory caching
 * - Coalesced: Optimizes memory access patterns for better throughput
 * - Compute-intensive: Adds controlled computation load for benchmarking
 */

/**
 * @brief Block-based Forward Elimination using Local Memory
 * 
 * Strategy 1: This implementation uses shared/local memory to cache the pivot row,
 * reducing global memory access and improving performance on memory-bound systems.
 * 
 * Optimization techniques:
 * 1. Shared memory caching of pivot row
 * 2. Cooperative loading of pivot data
 * 3. Complete row processing by each work item
 * 4. Barrier synchronization for cache coherency
 * 
 * Memory access pattern:
 * - Cooperative loading: Strided access to global memory
 * - Processing: Sequential access within each row
 * - Local memory: High-speed access to pivot data
 */
__kernel void forwardEliminationBlocked(
    __global float* matrix,
    __global float* b,
    int n,
    int pivot_row,
    __local float* pivot_cache    // Shared memory for pivot row
)
{
    int tid = get_local_id(0);
    int wg_size = get_local_size(0);
    int gid = get_global_id(0);
    int row = gid + pivot_row + 1; // Start from the row after pivot
    
    if (row >= n) return;
    
    // Cooperatively load pivot row into shared memory
    int pivot_elements = n - pivot_row;
    for (int i = tid; i < pivot_elements; i += wg_size) {
        if (pivot_row + i < n) {
            pivot_cache[i] = matrix[pivot_row * n + pivot_row + i];
        }
    }
    
    // Cache pivot b value at the end of the cache
    if (tid == 0) {
        pivot_cache[pivot_elements] = b[pivot_row];
    }
    
    barrier(CLK_LOCAL_MEM_FENCE);
    
    // Calculate elimination factor
    float pivot_element = pivot_cache[0]; // matrix[pivot_row][pivot_row]
    if (fabs(pivot_element) < 1e-10f) return; // Avoid division by zero
    
    float factor = matrix[row * n + pivot_row] / pivot_element;
    
    // FIXED: Each work item processes its entire row sequentially
    // This eliminates race conditions between work items
    for (int col = pivot_row; col < n; col++) {
        int cache_idx = col - pivot_row;
        matrix[row * n + col] -= factor * pivot_cache[cache_idx];
    }
    
    // Update RHS vector - each work item updates its own row
    b[row] -= factor * pivot_cache[pivot_elements];
}

/**
 * @brief Coalesced Memory Access Forward Elimination
 * 
 * Strategy 2: This implementation optimizes memory access patterns by having
 * each thread process a single matrix element, enabling coalesced memory access.
 * 
 * Optimization techniques:
 * 1. Fine-grained parallelism: one thread per matrix element
 * 2. Coalesced memory access pattern
 * 3. Minimal thread synchronization
 * 4. Efficient work distribution
 * 
 * Memory access pattern:
 * - Global memory: Coalesced access for matrix elements
 * - Thread mapping: 2D grid mapped to 1D thread array
 * - RHS vector: Atomic updates by first thread in each row
 * 
 * Performance characteristics:
 * - Better for memory bandwidth-limited systems
 * - Reduced thread divergence
 * - Higher parallelism than block-based version
 */
__kernel void forwardEliminationCoalesced(
    __global float* matrix,
    __global float* b,
    int n,
    int pivot_row
)
{
    int gid = get_global_id(0);
    
    // Calculate which row and column this thread handles
    int remaining_rows = n - pivot_row - 1;
    int remaining_cols = n - pivot_row;
    
    if (remaining_rows <= 0 || remaining_cols <= 0) return;
    
    int total_elements = remaining_rows * remaining_cols;
    if (gid >= total_elements) return;
    
    int row_offset = gid / remaining_cols;
    int col_offset = gid % remaining_cols;
    
    int row = pivot_row + 1 + row_offset;
    int col = pivot_row + col_offset;
    
    if (row >= n || col >= n) return;
    
    // Load pivot element
    float pivot_element = matrix[pivot_row * n + pivot_row];
    if (fabs(pivot_element) < 1e-10f) return;
    
    // Calculate factor for this row (each thread in the same row will compute the same factor)
    float factor = matrix[row * n + pivot_row] / pivot_element;
    
    // Perform elimination - each thread handles one element
    matrix[row * n + col] -= factor * matrix[pivot_row * n + col];
    
    // Update b vector (only first thread of each row)
    if (col_offset == 0) {
        b[row] -= factor * b[pivot_row];
    }
}

/**
 * @brief Compute-Intensive Forward Elimination for Benchmarking
 * 
 * This kernel is a modified version of the coalesced implementation that adds
 * controlled computational intensity for benchmarking purposes. It helps analyze
 * how the algorithm behaves under different compute/memory ratios.
 * 
 * Optimization techniques:
 * 1. Maintains coalesced memory access pattern
 * 2. Adds configurable computation load
 * 3. Prevents compiler optimization of the added computation
 * 4. Preserves numerical stability
 * 
 * Benchmarking features:
 * - Configurable loop count for compute intensity
 * - Numerically stable accumulation
 * - Minimal impact on result accuracy
 * - Controlled memory access pattern
 * 
 * @param matrix     Input/Output matrix in row-major order [n x n]
 * @param b          Input/Output RHS vector [n]
 * @param n          Matrix dimension
 * @param pivot_row  Current pivot row
 * @param loop_count Number of computation iterations for benchmarking
 */
__kernel void forwardEliminationCoalescedIntensive(
    __global float* matrix,
    __global float* b,
    int n,
    int pivot_row,
    int loop_count
)
{
    int gid = get_global_id(0);
    
    int remaining_rows = n - pivot_row - 1;
    int remaining_cols = n - pivot_row;
    
    if (remaining_rows <= 0 || remaining_cols <= 0) return;
    
    int total_elements = remaining_rows * remaining_cols;
    if (gid >= total_elements) return;
    
    int row_offset = gid / remaining_cols;
    int col_offset = gid % remaining_cols;
    
    int row = pivot_row + 1 + row_offset;
    int col = pivot_row + col_offset;
    
    if (row >= n || col >= n) return;
    
    float pivot_element = matrix[pivot_row * n + pivot_row];
    if (fabs(pivot_element) < 1e-10f) return;
    
    float factor = matrix[row * n + pivot_row] / pivot_element;
    float pivot_value = matrix[pivot_row * n + col];
    
    // FIXED: Make the loop actually do work that affects the result
    // Method 1: Accumulate with slight variations
    float accumulated_factor = factor;
    for (int j = 1; j < loop_count; j++) {
        // Slightly modify the factor each iteration so compiler can't optimize
        accumulated_factor += factor * (j * 1e-10f);  // Very small change
        accumulated_factor *= 0.999999f;              // Prevent overflow
        accumulated_factor += factor * 1e-10f;        // Add back to maintain magnitude
    }
    
    // Use the accumulated result (will be very close to original factor)
    matrix[row * n + col] -= accumulated_factor * pivot_value;
    
    if (col_offset == 0) {
        b[row] -= factor * b[pivot_row];  // Keep b update simple
    }
}


/**
 * @brief Optimized Back Substitution Kernel
 * 
 * This kernel performs the back substitution phase after forward elimination.
 * Due to data dependencies, this phase is inherently sequential and runs on a single thread.
 * However, it includes optimizations for numerical stability and error handling.
 * 
 * Optimization techniques:
 * 1. Single thread execution to avoid synchronization overhead
 * 2. Numerical stability checks
 * 3. Singular matrix handling
 * 4. Sequential memory access pattern
 * 
 * Error handling:
 * - Checks for near-zero diagonal elements
 * - Handles singular matrices gracefully
 * - Sets solution to zero for singular cases
 * 
 * @param matrix Input matrix in row-major order [n x n], now in upper triangular form
 * @param b      Input RHS vector [n], modified by forward elimination
 * @param x      Output solution vector [n]
 * @param n      Matrix dimension
 */
__kernel void backSubstitution(
    __global float* matrix,
    __global float* b,
    __global float* x,
    int n
)
{
    int tid = get_global_id(0);
    
    if (tid != 0) return; // Only thread 0 does the work
    
    // Back substitution - must be done sequentially
    for (int i = n - 1; i >= 0; i--) {
        float sum = b[i];
        for (int j = i + 1; j < n; j++) {
            sum -= matrix[i * n + j] * x[j];
        }
        
        float diagonal = matrix[i * n + i];
        if (fabs(diagonal) > 1e-10f) {
            x[i] = sum / diagonal;
        } else {
            x[i] = 0.0f; // Handle singular case
        }
    }
}

